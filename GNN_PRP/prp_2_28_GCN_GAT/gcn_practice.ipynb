{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "setup_seed(999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTRODUCTION BY EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "data = Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G = to_networkx(data, to_undirected=True)\n",
    "nx.draw(G, pos=nx.spiral_layout(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 1., 0.],\n",
       "        [1., 0., 1.],\n",
       "        [0., 1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = nx.to_numpy_matrix(G)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root='/tmp/IMDB', name='IMDB-BINARY', use_node_attr=True).shuffle()\n",
    "data_sz = len(dataset)\n",
    "x0, x1 = round(0.8*data_sz), round(0.9*data_sz)\n",
    "train_set, validation_set, test_set = dataset[0:x0], dataset[x0:x1], dataset[x1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 100, 100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(validation_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summation(batch):\n",
    "    edge = 0\n",
    "    node = 0\n",
    "    for x, _ in enumerate(batch.y):\n",
    "        edge += batch[x].edge_index.shape[1]\n",
    "        node += batch[x].num_nodes\n",
    "    return edge, node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 (5108, 628) DataBatch(edge_index=[2, 5108], y=[32], num_nodes=628, batch=[628], ptr=[33])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch.num_graphs, summation(batch), batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CREATING MESSAGE PASSING NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myGCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_normal_(self.lin.weight.data)\n",
    "    def forward(self, x, edge_index):\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        x = self.lin(x)\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MessagePassing (related functions)\n",
    "- forward\n",
    "- messsage\n",
    "- propagate\n",
    "- update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = myGCNConv(16, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MEMORY-EFFICIENT AGGREGATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_sparse import matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myGINConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, eps=1e-5):\n",
    "        super().__init__(aggr='add')\n",
    "        self.mlp = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.eps = eps\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.kaiming_normal_(self.mlp.weight.data)\n",
    "                \n",
    "    def forward(self, x, edge_index):\n",
    "        out = self.propagate(edge_index, x=x)\n",
    "        return self.mlp((1+self.eps)*x + out)\n",
    "    \n",
    "    def message(self, x_j):\n",
    "        return x_j\n",
    "    \n",
    "    def message_aggregate(self, adj_t, x):\n",
    "        return matmul(adj_t, x, reduce=self.aggr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, BatchNorm1d, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SELF-DESIGNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_layers, out_channels, eps=1e-4, aggr = \"add\", activation_fn=None):\n",
    "        super().__init__()\n",
    "        assert aggr in ['add', 'mean', 'max']\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channles = hidden_channels\n",
    "        self.num_layers = num_layers\n",
    "        self.out_channels = out_channels\n",
    "        self.eps = eps\n",
    "        self.aggr = aggr\n",
    "        self.activation_fn = activation_fn\n",
    "        \n",
    "        if num_layers == 1:\n",
    "            self.lin = torch.nn.ModuleList([Linear(in_channels, out_channels, bias=False)])\n",
    "        else:\n",
    "            self.lin = torch.nn.ModuleList([Linear(in_channels, hidden_channels, bias=False)])\n",
    "            self.lin.extend([Linear(hidden_channels, hidden_channels, bias=False) for x in range(num_layers-2)])\n",
    "            self.lin.extend([Linear(hidden_channels, out_channels, bias=False)])\n",
    "        self.bns = torch.nn.ModuleList([BatchNorm1d(hidden_channels) for x in range(num_layers-1)])\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        for net in self.lin:\n",
    "            torch.nn.init.kaiming_normal_(net.weight.data)\n",
    "        for net in self.bns:\n",
    "            torch.nn.init.ones_(net.weight.data)\n",
    "        \n",
    "    def message_and_aggregate(self, adj_t, x):\n",
    "        return matmul(adj_t, x, reduce=self.aggr)\n",
    "    \n",
    "    def update(self, inputs):\n",
    "        return inputs\n",
    "    \n",
    "    def propagate(self, x, edge_index):\n",
    "        return (1 + self.eps)*x + self.message_and_aggregate(edge_index, x)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        out = self.propagate(x, edge_index)\n",
    "        for l in range(self.num_layers):\n",
    "            out = self.lin[l](out)\n",
    "            if l != self.num_layers-1:\n",
    "                out = self.bns[l](out)\n",
    "                x = F.relu6(x)\n",
    "                out = F.dropout(out, training=self.training)\n",
    "        if self.activation_fn:\n",
    "            out = self.activation_fn(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
    "                 dropout, return_embeds=False):\n",
    "        # TODO: Implement a function that initializes self.convs, \n",
    "        # self.bns, and self.softmax.\n",
    "\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # A list of GCNConv layers\n",
    "        self.convs = None\n",
    "\n",
    "        # A list of 1D batch normalization layers\n",
    "        self.bns = None\n",
    "\n",
    "        # The log softmax layer\n",
    "        self.softmax = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. You should use torch.nn.ModuleList for self.convs and self.bns\n",
    "        ## 2. self.convs has num_layers GCNConv layers\n",
    "        ## 3. self.bns has num_layers - 1 BatchNorm1d layers\n",
    "        ## 4. You should use torch.nn.LogSoftmax for self.softmax\n",
    "        ## 5. The parameters you can set for GCNConv include 'in_channels' and \n",
    "        ## 'out_channels'. For more information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv\n",
    "        ## 6. The only parameter you need to set for BatchNorm1d is 'num_features'\n",
    "        ## For more information please refer to the documentation: \n",
    "        ## https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n",
    "        ## (~10 lines of code)\n",
    "        self.convs = torch.nn.ModuleList([GCNConv(input_dim, hidden_dim)])\n",
    "        self.convs.extend([GCNConv(hidden_dim, hidden_dim) for x in range(num_layers-2)])\n",
    "        self.convs.extend([GCNConv(hidden_dim, output_dim)])\n",
    "        \n",
    "        self.bns = torch.nn.ModuleList([BatchNorm1d(hidden_dim) for x in range(num_layers-1)])\n",
    "\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "        self.num_layers = num_layers\n",
    "        #########################################\n",
    "\n",
    "        # Probability of an element getting zeroed\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Skip classification layer and return node embeddings\n",
    "        self.return_embeds = return_embeds\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        # TODO: Implement a function that takes the feature tensor x and\n",
    "        # edge_index tensor adj_t and returns the output tensor as\n",
    "        # shown in the figure.\n",
    "\n",
    "        out = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Construct the network as shown in the figure\n",
    "        ## 2. torch.nn.functional.relu and torch.nn.functional.dropout are useful\n",
    "        ## For more information please refer to the documentation:\n",
    "        ## https://pytorch.org/docs/stable/nn.functional.html\n",
    "        ## 3. Don't forget to set F.dropout training to self.training\n",
    "        ## 4. If return_embeds is True, then skip the last softmax layer\n",
    "        ## (~7 lines of code)\n",
    "        for depth, conv in enumerate(self.convs):\n",
    "            x = conv(x, adj_t)\n",
    "            if depth == self.num_layers - 1:\n",
    "                out = x if self.return_embeds else self.softmax(x)\n",
    "            else:\n",
    "                x = self.bns[depth](x)\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        #########################################\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "dataset_name = 'ogbn-arxiv'\n",
    "dataset = PygNodePropPredDataset(name=dataset_name,\n",
    "                                transform=T.ToSparseTensor())\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_484009/3321475947.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Device: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0msplit_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_idx_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtrain_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gnn/lib/python3.8/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    214\u001b[0m         r\"\"\"Performs tensor device conversion, either for all attributes or\n\u001b[1;32m    215\u001b[0m         only the ones given in :obj:`*args`.\"\"\"\n\u001b[0;32m--> 216\u001b[0;31m         return self.apply(\n\u001b[0m\u001b[1;32m    217\u001b[0m             lambda x: x.to(device=device, non_blocking=non_blocking), *args)\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gnn/lib/python3.8/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    202\u001b[0m         the ones given in :obj:`*args`.\"\"\"\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gnn/lib/python3.8/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    144\u001b[0m         the ones given in :obj:`*args`.\"\"\"\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecursive_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gnn/lib/python3.8/site-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPackedSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gnn/lib/python3.8/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    215\u001b[0m         only the ones given in :obj:`*args`.\"\"\"\n\u001b[1;32m    216\u001b[0m         return self.apply(\n\u001b[0;32m--> 217\u001b[0;31m             lambda x: x.to(device=device, non_blocking=non_blocking), *args)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Make the adjacency matrix to symmetric\n",
    "data.adj_t = data.adj_t.to_symmetric()\n",
    "\n",
    "device = 'cuda:3' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# If you use GPU, the device should be cuda\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "data = data.to(device)\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx = split_idx['train'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer, loss_fn):\n",
    "    # TODO: Implement a function that trains the model by \n",
    "    # using the given optimizer and loss_fn.\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## Note:\n",
    "    ## 1. Zero grad the optimizer\n",
    "    ## 2. Feed the data into the model\n",
    "    ## 3. Slice the model output and label by train_idx\n",
    "    ## 4. Feed the sliced output and label to loss_fn\n",
    "    ## (~4 lines of code)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.adj_t)\n",
    "    loss = loss_fn(output[train_idx], data.y[train_idx].squeeze(1))\n",
    "    #########################################\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function here\n",
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, evaluator, save_model_results=False):\n",
    "    # TODO: Implement a function that tests the model by \n",
    "    # using the given split_idx and evaluator.\n",
    "    model.eval()\n",
    "\n",
    "    # The output of model on all data\n",
    "    out = None\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## (~1 line of code)\n",
    "    ## Note:\n",
    "    ## 1. No index slicing here\n",
    "    out = model(data.x, data.adj_t)\n",
    "    #########################################\n",
    "\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })['acc']\n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })['acc']\n",
    "\n",
    "    if save_model_results:\n",
    "      print (\"Saving Model Predictions\")\n",
    "\n",
    "      data = {}\n",
    "      data['y_pred'] = y_pred.view(-1).cpu().detach().numpy()\n",
    "\n",
    "      df = pd.DataFrame(data=data)\n",
    "      # Save locally as csv\n",
    "      df.to_csv('ogbn-arxiv_node.csv', sep=',', index=False)\n",
    "\n",
    "\n",
    "    return train_acc, valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please do not change the args\n",
    "args = {\n",
    "    'device': device,\n",
    "    'num_layers': 4,\n",
    "    'hidden_dim': 128,\n",
    "    'dropout': 0.5,\n",
    "    'lr': 1e-2,\n",
    "    'epochs': 100,\n",
    "}\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "# reset the parameters to initial random value\n",
    "def model_choice(model, args):\n",
    "    evaluator = Evaluator(name='ogbn-arxiv')\n",
    "    model.reset_parameters()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "    loss_fn = F.nll_loss\n",
    "\n",
    "    best_model = None\n",
    "    best_valid_acc = 0\n",
    "\n",
    "    for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "        loss = train(model, data, train_idx, optimizer, loss_fn)\n",
    "        result = test(model, data, split_idx, evaluator)\n",
    "        train_acc, valid_acc, test_acc = result\n",
    "        if valid_acc > best_valid_acc:\n",
    "            best_valid_acc = valid_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "        print(f'Epoch: {epoch:02d}, '\n",
    "            f'Loss: {loss:.4f}, '\n",
    "            f'Train: {100 * train_acc:.2f}%, '\n",
    "            f'Valid: {100 * valid_acc:.2f}% '\n",
    "            f'Test: {100 * test_acc:.2f}%')\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = GCN(data.num_features, args['hidden_dim'],\n",
    "              dataset.num_classes, args['num_layers'],\n",
    "              args['dropout']).to(device)\n",
    "best_model1 = model_choice(model1, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['epochs'] = 256\n",
    "model2 = GCNLayer(\n",
    "    data.num_features, \n",
    "    args['hidden_dim'], \n",
    "    args['num_layers'], \n",
    "    dataset.num_classes,\n",
    "    eps=1e-2,\n",
    "    activation_fn=torch.nn.LogSoftmax(dim=1)\n",
    ").to(device)\n",
    "best_model2 = model_choice(model2, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model1, \"model1.pth\")\n",
    "torch.save(best_model2, \"model2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(name='ogbn-arxiv')\n",
    "test_score1 = test(best_model1, data, split_idx, evaluator)\n",
    "test_score2 = test(best_model2, data, split_idx, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame({\n",
    "    \"score\": list(test_score1) + list(test_score2), \n",
    "    \"model\": [*(['GCN']*3), *(['Self-designed']*3)],\n",
    "    \"mode\": [*([\"train\", \"valid\", \"test\"]*2)]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.pivot_table(values='score', columns='mode', index='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "sns.barplot(data=scores, x='mode', y='score', hue='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Perdict\n",
    "- why use global_max_pool (forgot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool\n",
    "\n",
    "class GCN_graph(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, out_dim, dropout):\n",
    "        super(GCN_graph, self).__init__()\n",
    "\n",
    "        self.node_encoder = AtomEncoder(hidden_dim)\n",
    "        self.gnn_node = GCN(hidden_dim, hidden_dim, hidden_dim, num_layers, dropout, return_embeds=True)\n",
    "\n",
    "        self.pool = global_max_pool\n",
    "        self.lin = Linear(hidden_dim, out_dim)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.gnn_node.reset_parameters()\n",
    "        self.lin.reset_parameters()\n",
    "\n",
    "    def forward(self, batched_data):\n",
    "        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n",
    "        \n",
    "        embed = self.node_encoder(x)\n",
    "        message = self.gnn_node(embed, edge_index)\n",
    "\n",
    "        out = self.pool(message, batch)\n",
    "        out = self.lin(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remain to understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_scatter\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch.nn import Parameter, Linear, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_sparse import SparseTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FAILED TRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, heads = 5, \n",
    "            negative_slope = 0.2, dropout = 0., **kwargs):\n",
    "        super(GAT, self).__init__(**kwargs)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.head = heads\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "        self.node_dim = 0\n",
    "\n",
    "        self.lin_l = Linear(in_channels, heads*out_channels)\n",
    "        self.lin_r = self.lin_l\n",
    "\n",
    "        self.att_l = Parameter(torch.randn(heads, out_channels))\n",
    "        self.att_r = Parameter(torch.randn(heads, out_channels))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.lin_l.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.lin_r.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.att_l)\n",
    "        torch.nn.init.xavier_uniform_(self.att_r)\n",
    "    \n",
    "    def message_and_propagate(self, edge_index, size, x, alpha):\n",
    "        x_l, _ = x\n",
    "        alpha_l, alpha_r = alpha\n",
    "        node_dim = self.node_dim\n",
    "        \n",
    "        new_i = torch.cat([alpha_r[x].unsqueeze(0) for x in edge_index[1]], dim=0)\n",
    "        new_j = torch.cat([alpha_l[x].unsqueeze(0) for x in edge_index[0]], dim=0)\n",
    "        new_x_j = torch.cat([x_l[x].unsqueeze(0) for x in edge_index[0]], dim=0)\n",
    "\n",
    "        alpha_ij = F.leaky_relu(new_i+new_j, negative_slope=self.negative_slope)\n",
    "        alpha_ij = softmax(alpha_ij, edge_index[1])\n",
    "        alpha_ij = F.dropout(alpha_ij, self.dropout)\n",
    "        out = alpha_ij * new_x_j        \n",
    "        out = torch_scatter.scatter(out, edge_index[1], node_dim, reduce='sum')\n",
    "        return out\n",
    "\n",
    "    def update(self, inputs):\n",
    "        return inputs\n",
    "\n",
    "    def propagate(self, edge_index, size, x, alpha):\n",
    "        out = self.message_and_propagate(edge_index, size, x, alpha)\n",
    "        return self.update(out)\n",
    "\n",
    "    def forward(self, x, edge_index, size=None):\n",
    "        H, C = self.head, self.out_channels\n",
    "        \n",
    "        x_l = self.lin_l(x).view(-1, H, C)\n",
    "        x_r = self.lin_r(x).view(-1, H, C)\n",
    "\n",
    "        alpha_l = self.att_l.unsqueeze(0) * x_l\n",
    "        alpha_r = self.att_r.unsqueeze(0) * x_r\n",
    "\n",
    "        out = self.propagate(edge_index, size, x=(x_l, x_r), alpha=(alpha_l, alpha_r))\n",
    "        out = out.view(-1, H*C)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GAT(MessagePassing):\n",
    "\n",
    "#     def __init__(self, in_channels, out_channels, heads = 2,\n",
    "#                  negative_slope = 0.2, dropout = 0., **kwargs):\n",
    "#         super(GAT, self).__init__(node_dim=0, **kwargs)\n",
    "#         self.in_channels = in_channels\n",
    "#         self.out_channels = out_channels\n",
    "#         self.heads = heads\n",
    "#         self.negative_slope = negative_slope\n",
    "#         self.dropout = dropout\n",
    "\n",
    "#         self.lin_l = None\n",
    "#         self.lin_r = None\n",
    "#         self.att_l = None\n",
    "#         self.att_r = None\n",
    "\n",
    "#         ############################################################################\n",
    "#         # TODO: Your code here! \n",
    "#         # Define the layers needed for the message functions below.\n",
    "#         # self.lin_l is the linear transformation that you apply to embeddings \n",
    "#         # BEFORE message passing.\n",
    "#         # \n",
    "#         # Pay attention to dimensions of the linear layers, since we're using \n",
    "#         # multi-head attention.\n",
    "#         # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
    "\n",
    "#         self.lin_l = Linear(self.in_channels, self.heads*self.out_channels)\n",
    "#         ############################################################################\n",
    "\n",
    "#         self.lin_r = self.lin_l\n",
    "\n",
    "#         ############################################################################\n",
    "#         # TODO: Your code here! \n",
    "#         # Define the attention parameters \\overrightarrow{a_l/r}^T in the above intro.\n",
    "#         # You have to deal with multi-head scenarios.\n",
    "#         # Use nn.Parameter instead of nn.Linear\n",
    "#         # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
    "\n",
    "#         self.att_l = Parameter(torch.randn(heads, self.out_channels))\n",
    "#         self.att_r = Parameter(torch.randn(heads, self.out_channels))\n",
    "#         ############################################################################\n",
    "\n",
    "#         self.reset_parameters()\n",
    "\n",
    "#     def reset_parameters(self):\n",
    "#         torch.nn.init.xavier_uniform_(self.lin_l.weight)\n",
    "#         torch.nn.init.xavier_uniform_(self.lin_r.weight)\n",
    "#         torch.nn.init.xavier_uniform_(self.att_l)\n",
    "#         torch.nn.init.xavier_uniform_(self.att_r)\n",
    "\n",
    "#     def forward(self, x, edge_index, size = None):\n",
    "        \n",
    "#         H, C = self.heads, self.out_channels\n",
    "\n",
    "#         ############################################################################\n",
    "#         # TODO: Your code here! \n",
    "#         # Implement message passing, as well as any pre- and post-processing (our update rule).\n",
    "#         # 1. First apply linear transformation to node embeddings, and split that \n",
    "#         #    into multiple heads. We use the same representations for source and\n",
    "#         #    target nodes, but apply different linear weights (W_l and W_r)\n",
    "#         # 2. Calculate alpha vectors for central nodes (alpha_l) and neighbor nodes (alpha_r).\n",
    "#         # 3. Call propagate function to conduct the message passing. \n",
    "#         #    3.1 Remember to pass alpha = (alpha_l, alpha_r) as a parameter.\n",
    "#         #    3.2 See there for more information: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
    "#         # 4. Transform the output back to the shape of [N, H * C].\n",
    "#         # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
    "\n",
    "#         x_l = self.lin_l(x).view(-1, H, C)\n",
    "#         x_r = self.lin_r(x).view(-1, H, C)\n",
    "        \n",
    "#         alpha_l = self.att_l.unsqueeze(0) * x_l\n",
    "#         alpha_r = self.att_r.unsqueeze(0) * x_r\n",
    "        \n",
    "#         out = self.propagate(edge_index=edge_index, size=size, x=(x_l, x_r), alpha=(alpha_l, alpha_r))\n",
    "#         out = out.view(-1, H*C)\n",
    "#         ############################################################################\n",
    "\n",
    "#         return out\n",
    "\n",
    "#     MessagePassing.message\n",
    "#     def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n",
    "\n",
    "#         ############################################################################\n",
    "#         # TODO: Your code here! \n",
    "#         # Implement your message function. Putting the attention in message \n",
    "#         # instead of in update is a little tricky.\n",
    "#         # 1. Calculate the final attention weights using alpha_i and alpha_j,\n",
    "#         #    and apply leaky Relu.\n",
    "#         # 2. Calculate softmax over the neighbor nodes for all the nodes. Use \n",
    "#         #    torch_geometric.utils.softmax instead of the one in Pytorch.\n",
    "#         # 3. Apply dropout to attention weights (alpha).\n",
    "#         # 4. Multiply embeddings and attention weights. As a sanity check, the output\n",
    "#         #    should be of shape [E, H, C].\n",
    "#         # 5. ptr (LongTensor, optional): If given, computes the softmax based on\n",
    "#         #    sorted inputs in CSR representation. You can simply pass it to softmax.\n",
    "#         # Our implementation is ~4-5 lines, but don't worry if you deviate from this.\n",
    "\n",
    "#         alpha_ij = F.leaky_relu(alpha_i+alpha_j, negative_slope=self.negative_slope)\n",
    "#         if ptr is not None:\n",
    "#             alpha_ij = torch_geometric.utils.softmax(alpha_ij, ptr)\n",
    "#         else:\n",
    "#             alpha_ij = torch_geometric.utils.softmax(alpha_ij, index)\n",
    "#         alpha_ij = F.dropout(alpha_ij, self.dropout)\n",
    "#         out = alpha_ij * x_j\n",
    "#         ############################################################################\n",
    "\n",
    "#         return out\n",
    "\n",
    "\n",
    "#     def aggregate(self, inputs, index, dim_size = None):\n",
    "\n",
    "#         ############################################################################\n",
    "#         # TODO: Your code here! \n",
    "#         # Implement your aggregate function here.\n",
    "#         # See here as how to use torch_scatter.scatter: https://pytorch-scatter.readthedocs.io/en/latest/_modules/torch_scatter/scatter.html\n",
    "#         # Pay attention to \"reduce\" parameter is different from that in GraphSage.\n",
    "#         # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
    "\n",
    "#         node_dim = self.node_dim\n",
    "#         out = torch_scatter.scatter(inputs, index, node_dim, reduce='sum')\n",
    "#         ############################################################################\n",
    "    \n",
    "#         return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GNNStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GNNStack(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):\n",
    "        super(GNNStack, self).__init__()\n",
    "        self.heads = args.heads\n",
    "        \n",
    "        conv_model = GAT\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(conv_model(input_dim, hidden_dim, heads=self.heads))\n",
    "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
    "        for l in range(args.num_layers-1):\n",
    "            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim, heads=self.heads))\n",
    "\n",
    "        # post-message-passing\n",
    "        self.post_mp = torch.nn.Sequential(\n",
    "            Linear(args.heads * hidden_dim, hidden_dim), Dropout(args.dropout), \n",
    "            Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.dropout = args.dropout\n",
    "        self.num_layers = args.num_layers\n",
    "\n",
    "        self.emb = emb\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "          \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout,training=self.training)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        if self.emb == True:\n",
    "            return x\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def build_optimizer(args, params):\n",
    "    weight_decay = args.weight_decay\n",
    "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
    "    if args.opt == 'adam':\n",
    "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'sgd':\n",
    "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
    "    elif args.opt == 'rmsprop':\n",
    "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    elif args.opt == 'adagrad':\n",
    "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
    "    if args.opt_scheduler == 'none':\n",
    "        return None, optimizer\n",
    "    elif args.opt_scheduler == 'step':\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
    "    elif args.opt_scheduler == 'cos':\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
    "    return scheduler, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def train(dataset, args):\n",
    "    \n",
    "    print(\"Node task. test set size:\", np.sum(dataset[0]['test_mask'].numpy()))\n",
    "    print()\n",
    "    test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
    "    # build model\n",
    "    model = GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes, \n",
    "                            args)\n",
    "    scheduler, opt = build_optimizer(args, model.parameters())\n",
    "\n",
    "    # train\n",
    "    losses = []\n",
    "    test_accs = []\n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            opt.zero_grad()\n",
    "            pred = model(batch)\n",
    "            label = batch.y\n",
    "            pred = pred[batch.train_mask]\n",
    "            label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        losses.append(total_loss)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "          test_acc = test(test_loader, model)\n",
    "          test_accs.append(test_acc)\n",
    "          if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "          test_accs.append(test_accs[-1])\n",
    "    \n",
    "    return test_accs, losses, best_model, best_acc, test_loader\n",
    "\n",
    "def test(loader, test_model, is_validation=False, save_model_preds=False, model_type=None):\n",
    "    test_model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    # Note that Cora is only one graph!\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            # max(dim=1) returns values, indices tuple; only need indices\n",
    "            pred = test_model(data).max(dim=1)[1]\n",
    "            label = data.y\n",
    "\n",
    "        mask = data.val_mask if is_validation else data.test_mask\n",
    "        # node classification: only evaluate on nodes in test set\n",
    "        pred = pred[mask]\n",
    "        label = label[mask]\n",
    "\n",
    "        if save_model_preds:\n",
    "          print (\"Saving Model Predictions for Model Type\", model_type)\n",
    "\n",
    "          data = {}\n",
    "          data['pred'] = pred.view(-1).cpu().detach().numpy()\n",
    "          data['label'] = label.view(-1).cpu().detach().numpy()\n",
    "\n",
    "          df = pd.DataFrame(data=data)\n",
    "          # Save locally as csv\n",
    "          df.to_csv('CORA-Node-' + model_type + '.csv', sep=',', index=False)\n",
    "            \n",
    "        correct += pred.eq(label).sum().item()\n",
    "\n",
    "    total = 0\n",
    "    for data in loader.dataset:\n",
    "        total += torch.sum(data.val_mask if is_validation else data.test_mask).item()\n",
    "\n",
    "    return correct / total\n",
    "  \n",
    "class objectview(object):\n",
    "    def __init__(self, d):\n",
    "        self.__dict__ = d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for args in [\n",
    "    {'device': 'cpu', 'model_type': 'GAT', 'dataset': 'cora', 'num_layers': 2, 'batch_size': 32, 'hidden_dim': 32, 'dropout': 0.5, 'epochs': 500, 'opt': 'adam', 'opt_scheduler': 'none', 'opt_restart': 0, 'weight_decay': 5e-3, 'lr': 0.01},\n",
    "]:\n",
    "    args = objectview(args)\n",
    "for model in ['GAT']:\n",
    "    args.model_type = model\n",
    "\n",
    "    # Match the dimension.\n",
    "    if model == 'GAT':\n",
    "        args.heads = 3\n",
    "    else:\n",
    "        args.heads = 1\n",
    "\n",
    "    if args.dataset == 'cora':\n",
    "        dataset = Planetoid(root='/tmp/cora', name='Cora')\n",
    "    else:\n",
    "        raise NotImplementedError(\"Unknown dataset\") \n",
    "    test_accs, losses, best_model, best_acc, test_loader = train(dataset, args) \n",
    "\n",
    "    print(\"Maximum test set accuracy: {0}\".format(max(test_accs)))\n",
    "    print(\"Minimum loss: {0}\".format(min(losses)))\n",
    "\n",
    "    # Run test for our best model to save the predictions!\n",
    "    test(test_loader, best_model, is_validation=False, save_model_preds=True, model_type=model)\n",
    "    print()\n",
    "\n",
    "    plt.title(dataset.name)\n",
    "    plt.plot(losses, label=\"training loss\" + \" - \" + args.model_type)\n",
    "    plt.plot(test_accs, label=\"test accuracy\" + \" - \" + args.model_type)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2708*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root='/tmp/cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 3, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ce0e62306dd6a5716965d4519ada776f947e6dfc145b604b11307c10277ef29"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
